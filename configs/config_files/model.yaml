MODEL:
  CONTEXT_WINDOW_SIZE: 4096
  N_GPU_LAYERS: 40  # Llama-2-70B has 83 layers
  N_BATCH: 512
  DEVICE: 'cpu' # ["cpu", "cuda", "ipu", "xpu", "mkldnn", "opengl", "opencl", "ideep", "hip", 
                #  "ve", "fpga", "ort", "xla", "lazy", "vulkan", "mps", "meta", "hpu", "mtia"]

  SIMILARITY_THRESHOLD: 0.8

  USE_HISTORY: FALSE
  USE_RETRIEVER: TRUE

  SYSTEM_PROMPT: "
    Bạn là một trợ lý ảo hữu ích, bạn sẽ sử dụng ngữ cảnh được cung cấp để trả lời các câu hỏi của người dùng. 
    Hãy đọc ngữ cảnh được cung cấp trước khi trả lời câu hỏi và suy nghĩ từng bước.
  "

  MODEL_TYPE: "llama" # ["llama", "mistral", "non_llama"],
  EMBEDDING_MODEL_NAME: "intfloat/multilingual-e5-base"
  # MODEL_ID: "vilm/vinallama-7b-chat-GGUF"
  # MODEL_BASENAME: "vinallama-7b-chat_q5_0.gguf"

  MODEL_ID: "TheBloke/Mistral-7B-Instruct-v0.2-GGUF"
  MODEL_BASENAME: "mistral-7b-instruct-v0.2.Q6_K.gguf"

  # MODEL_ID: "TheBloke/TinyLlama-1.1B-Chat-v0.3-GGUF"
  # MODEL_BASENAME: "tinyllama-1.1b-chat-v0.3.Q6_K.gguf"

  # MODEL_ID: "TinyLlama/TinyLlama-1.1B-Chat-v1.0"
  # MODEL_BASENAME: None

    